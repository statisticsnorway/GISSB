as_data_frame = TRUE)
### Arrow (JSON) ###
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
JsonTableReader$create(block_size = 123654687456),
as_data_frame = TRUE)
library(dbplyr)
library(bigrquery)
library(dplyr)
library(googleCloudStorageR)
library(gargle)
library(arrow)
access_token <- getPass::getPass("Skriv inn access_token")
expiration <- as.numeric(getPass::getPass("Skriv inn expiration"))
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/2021",
access_token  = access_token,
expiration = expiration)
df_1 <- arrow::read_parquet(bucket$path("g2021_sysskostra.parquet"), as_data_frame = TRUE)
### Arrow (JSON) ###
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
JsonTableReader$create(block_size = 123654687456),
as_data_frame = TRUE)
df_2 <- arrow::read_json_arrow(JsonTableReader$create(file = bucket$path("testfil.json"), block_size = 123654687456),
as_data_frame = TRUE)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
as_data_frame = TRUE)
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#' Read a JSON file
#'
#' Wrapper around [JsonTableReader] to read a newline-delimited JSON (ndjson) file into a
#' data frame or Arrow Table.
#'
#' If passed a path, will detect and handle compression from the file extension
#' (e.g. `.json.gz`). Accepts explicit or implicit nulls.
#'
#' @inheritParams read_delim_arrow
#' @param schema [Schema] that describes the table.
#' @param ... Additional options passed to `JsonTableReader$create()`
#'
#' @return A `data.frame`, or a Table if `as_data_frame = FALSE`.
#' @export
#' @examplesIf arrow_with_json()
#' tf <- tempfile()
#' on.exit(unlink(tf))
#' writeLines('
#'     { "hello": 3.5, "world": false, "yo": "thing" }
#'     { "hello": 3.25, "world": null }
#'     { "hello": 0.0, "world": true, "yo": null }
#'   ', tf, useBytes = TRUE)
#' df <- read_json_arrow(tf)
read_json_arrow <- function(file,
col_select = NULL,
as_data_frame = TRUE,
schema = NULL,
...) {
if (!inherits(file, "InputStream")) {
compression <- detect_compression(file)
file <- make_readable_file(file)
if (compression != "uncompressed") {
# TODO: accept compression and compression_level as args
file <- CompressedInputStream$create(file, compression)
}
on.exit(file$close())
}
tab <- JsonTableReader$create(file, schema = schema, ...)$Read()
col_select <- enquo(col_select)
if (!quo_is_null(col_select)) {
tab <- tab[vars_select(names(tab), !!col_select)]
}
if (isTRUE(as_data_frame)) {
tab <- as.data.frame(tab)
}
tab
}
#' @include arrow-object.R
#' @rdname CsvTableReader
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonTableReader <- R6Class("JsonTableReader",
inherit = ArrowObject,
public = list(
Read = function() json___TableReader__Read(self)
)
)
library(R6)
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#' Read a JSON file
#'
#' Wrapper around [JsonTableReader] to read a newline-delimited JSON (ndjson) file into a
#' data frame or Arrow Table.
#'
#' If passed a path, will detect and handle compression from the file extension
#' (e.g. `.json.gz`). Accepts explicit or implicit nulls.
#'
#' @inheritParams read_delim_arrow
#' @param schema [Schema] that describes the table.
#' @param ... Additional options passed to `JsonTableReader$create()`
#'
#' @return A `data.frame`, or a Table if `as_data_frame = FALSE`.
#' @export
#' @examplesIf arrow_with_json()
#' tf <- tempfile()
#' on.exit(unlink(tf))
#' writeLines('
#'     { "hello": 3.5, "world": false, "yo": "thing" }
#'     { "hello": 3.25, "world": null }
#'     { "hello": 0.0, "world": true, "yo": null }
#'   ', tf, useBytes = TRUE)
#' df <- read_json_arrow(tf)
read_json_arrow <- function(file,
col_select = NULL,
as_data_frame = TRUE,
schema = NULL,
...) {
if (!inherits(file, "InputStream")) {
compression <- detect_compression(file)
file <- make_readable_file(file)
if (compression != "uncompressed") {
# TODO: accept compression and compression_level as args
file <- CompressedInputStream$create(file, compression)
}
on.exit(file$close())
}
tab <- JsonTableReader$create(file, schema = schema, ...)$Read()
col_select <- enquo(col_select)
if (!quo_is_null(col_select)) {
tab <- tab[vars_select(names(tab), !!col_select)]
}
if (isTRUE(as_data_frame)) {
tab <- as.data.frame(tab)
}
tab
}
#' @include arrow-object.R
#' @rdname CsvTableReader
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonTableReader <- R6Class("JsonTableReader",
inherit = ArrowObject,
public = list(
Read = function() json___TableReader__Read(self)
)
)
JsonTableReader$create <- function(file,
read_options = JsonReadOptions$create(),
parse_options = JsonParseOptions$create(schema = schema),
schema = NULL,
...) {
assert_is(file, "InputStream")
json___TableReader__Make(file, read_options, parse_options)
}
#' @rdname CsvReadOptions
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonReadOptions <- R6Class("JsonReadOptions", inherit = ArrowObject)
JsonReadOptions$create <- function(use_threads = option_use_threads(), block_size = 1048576L) {
json___ReadOptions__initialize(use_threads, block_size)
}
#' @rdname CsvReadOptions
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonParseOptions <- R6Class("JsonParseOptions", inherit = ArrowObject)
JsonParseOptions$create <- function(newlines_in_values = FALSE, schema = NULL) {
if (is.null(schema)) {
json___ParseOptions__initialize1(newlines_in_values)
} else {
json___ParseOptions__initialize2(newlines_in_values, schema)
}
}
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
as_data_frame = TRUE)
access_token <- getPass::getPass("Skriv inn access_token")
expiration <- as.numeric(getPass::getPass("Skriv inn expiration"))
### Arrow (JSON) ###
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
as_data_frame = TRUE)
head(df_2)
df_2$description
df_3 <- read_json_arrow(bucket$path("historic.json"),
as_data_frame = TRUE)
library(R6)
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#' Read a JSON file
#'
#' Wrapper around [JsonTableReader] to read a newline-delimited JSON (ndjson) file into a
#' data frame or Arrow Table.
#'
#' If passed a path, will detect and handle compression from the file extension
#' (e.g. `.json.gz`). Accepts explicit or implicit nulls.
#'
#' @inheritParams read_delim_arrow
#' @param schema [Schema] that describes the table.
#' @param ... Additional options passed to `JsonTableReader$create()`
#'
#' @return A `data.frame`, or a Table if `as_data_frame = FALSE`.
#' @export
#' @examplesIf arrow_with_json()
#' tf <- tempfile()
#' on.exit(unlink(tf))
#' writeLines('
#'     { "hello": 3.5, "world": false, "yo": "thing" }
#'     { "hello": 3.25, "world": null }
#'     { "hello": 0.0, "world": true, "yo": null }
#'   ', tf, useBytes = TRUE)
#' df <- read_json_arrow(tf)
read_json_arrow <- function(file,
col_select = NULL,
as_data_frame = TRUE,
schema = NULL,
...) {
if (!inherits(file, "InputStream")) {
compression <- detect_compression(file)
file <- make_readable_file(file)
if (compression != "uncompressed") {
# TODO: accept compression and compression_level as args
file <- CompressedInputStream$create(file, compression)
}
on.exit(file$close())
}
tab <- JsonTableReader$create(file, schema = schema, ...)$Read()
col_select <- enquo(col_select)
if (!quo_is_null(col_select)) {
tab <- tab[vars_select(names(tab), !!col_select)]
}
if (isTRUE(as_data_frame)) {
tab <- as.data.frame(tab)
}
tab
}
#' @include arrow-object.R
#' @rdname CsvTableReader
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonTableReader <- R6Class("JsonTableReader",
inherit = ArrowObject,
public = list(
Read = function() json___TableReader__Read(self)
)
)
JsonTableReader$create <- function(file,
read_options = JsonReadOptions$create(),
parse_options = JsonParseOptions$create(schema = schema),
schema = NULL,
...) {
assert_is(file, "InputStream")
json___TableReader__Make(file, read_options, parse_options)
}
#' @rdname CsvReadOptions
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonReadOptions <- R6Class("JsonReadOptions", inherit = ArrowObject)
JsonReadOptions$create <- function(use_threads = option_use_threads(), block_size = 10485761048576L) {
json___ReadOptions__initialize(use_threads, block_size)
}
#' @rdname CsvReadOptions
#' @usage NULL
#' @format NULL
#' @docType class
#' @export
JsonParseOptions <- R6Class("JsonParseOptions", inherit = ArrowObject)
JsonParseOptions$create <- function(newlines_in_values = FALSE, schema = NULL) {
if (is.null(schema)) {
json___ParseOptions__initialize1(newlines_in_values)
} else {
json___ParseOptions__initialize2(newlines_in_values, schema)
}
}
df_3 <- read_json_arrow(bucket$path("historic.json"),
as_data_frame = TRUE)
# install.packages("dbplyr")
# install.packages("bigrquery")
# devtools::install_version("dbplyr", version = "2.1.1", repos = "http://cran.us.r-project.org")
library(dbplyr)
library(bigrquery)
library(dplyr)
library(googleCloudStorageR)
library(gargle)
bigrquery::bq_auth()
### Arrow (parquet) ###
access_token <- "ya29.a0Aa4xrXM5mj6Q4CKI83cfw9-4JVT3V9sbFZt_lHhBAqNQwZM75hLRqRYOlxAvdFiRi0ulsSwoqqzMxtxW43459kLpuVn1cXF7HSUfKNyYzNLY1Vp7hpaBn-e6Hhb-BdtaPzU7ar7rGodYG7gO0UrGS0jcAZ-vaCgYKATASARISFQEjDvL92WT19AVwMkm5Ds_uTVBr6Q0163"
# access_token <- getPass::getPass("Skriv inn access_token")
expiration <- "1665152926"
### Arrow (JSON) ###
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
as_data_frame = TRUE)
# access_token <- getPass::getPass("Skriv inn access_token")
expiration <- 1665152926
### Arrow (JSON) ###
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
as_data_frame = TRUE)
test_df2 <- rjson::fromJSON(file = "C:/Users/rdn/Downloads/historic.json") %>%
as.data.frame()
### Arrow (JSON) ###
# test_df <- jsonlite::fromJSON("C:/Users/rdn/Downloads/historic.json") %>%
#   as.data.frame()
library(tidyverse)
test_df2 <- rjson::fromJSON(file = "C:/Users/rdn/Downloads/historic.json") %>%
as.data.frame()
df_2$data
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
as_data_frame = TRUE)
View(df_2)
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
# col_select = "result",
as_data_frame = F)
View(test_df2)
test_df2 <- test_df2[,1]
test_df2 <- rjson::fromJSON(file = "C:/Users/rdn/Downloads/historic.json") %>%
as.data.frame()
test_df3 <- test_df2[1,]
test_df3 <- test_df2[1]
View(test_df3)
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
col_select = "count",
as_data_frame = F)
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
col_select = "result",
as_data_frame = F)
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
# ?arrow::read_json_arrow
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
col_select = "result",
as_data_frame = F)
# ?arrow::read_json_arrow
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
col_select = "result.count",
as_data_frame = F)
# ?arrow::read_json_arrow
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
col_select = "result.count",
as_data_frame = F)
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
# ?arrow::read_json_arrow
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
col_select = "result.count",
as_data_frame = F)
head(df_2)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
schema = ""
as_data_frame = F)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
# schema = ""
as_data_frame = F)
### Arrow (JSON) ###
bucket <- arrow::gs_bucket("ssb-prod-spesh-personell-data-kilde/",
access_token  = access_token,
expiration = expiration)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
# schema = ""
as_data_frame = F)
df_2
df_2$schema
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
schema = schema(data = int32()),
as_data_frame = F)
### Arrow (JSON) ###
?arrow::read_json_arrow
### Arrow (JSON) ###
library(arrow)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
schema = schema(data = int32()),
as_data_frame = F)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
schema = schema(data = int32()),
as_data_frame = T)
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
# schema = schema(data = int32()),
as_data_frame = T)
df_2$schema
df_2 <- arrow::read_json_arrow(bucket$path("testfil.json"),
# JsonTableReader$create(block_size = 123654687456),
col_select = "data",
schema(data = int32()),
as_data_frame = T)
# ?arrow::read_json_arrow
df_3 <- arrow::read_json_arrow(bucket$path("historic.json"),
# col_select = "result.count",
as_data_frame = F)
head(df_2)
df_2$data
library(arrow)
test <- read_json_arrow("C:/Users/rdn/Downloads/historic.json")
read_json_arrow
test <- read.csv2("C:/Users/rdn/Documents/1987.csv")
head(test)
test <- read.csv2("C:/Users/rdn/Documents/1987.csv", sep = ",")
View(test)
arrow::write_parquet(test, "C:/Users/rdn/Documents/1987.parquet")
print"æ"
print"æ"
print"æ"
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
print("æ")
1+1
1+1
print("æ")
rint("æ")
print("æ")
'print("æ")
print("æ")
print("æ")
# print("æ")
.libPaths("C:/Users/rdn/Documents")
1+1
# print("æ")
.libPaths("C:/Users/rdn/Documents")
